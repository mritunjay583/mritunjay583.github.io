<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>DATAMART</title>
    <link>http://mritunjay583.github.io/docs/docs/usage-guidelines/</link>
    <description>Recent content on DATAMART</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 26 Mar 2019 08:47:11 +0100</lastBuildDate><atom:link href="http://mritunjay583.github.io/docs/docs/usage-guidelines/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>create index in dmdb</title>
      <link>http://mritunjay583.github.io/docs/docs/usage-guidelines/create-indexes-in-dmdb-guidlines/</link>
      <pubDate>Tue, 26 Mar 2019 08:47:11 +0100</pubDate>
      
      <guid>http://mritunjay583.github.io/docs/docs/usage-guidelines/create-indexes-in-dmdb-guidlines/</guid>
      <description>Using the following doc requires you the name of the table. If you don&amp;rsquo;t know the tablename here&amp;rsquo;s a doc through which you can find out here - #   navigation-around-views-and-tables after reading this.
 List Already Existing Index on a tables #  -- For listing all indexes on all partititioned table name select * from pg_indexes where schemaname = &#39;partitioned&#39;; -- For listing all indexes on all standalone table name select * from pg_indexes where schemaname = &#39;standalone&#39;; -- For listing all indexes on package__wbn__latest_prtd partititioned table select * from pg_indexes where schemaname = &#39;partitioned&#39; and tablename = &#39;package__wbn__latest_prtd&#39;; -- For listing all indexes on package_scan__wbn_cs_uid__latest_prtd partititioned table select * from pg_indexes where schemaname = &#39;standalone&#39; and tablename = &#39;facility__facility_code__latest_std&#39;; To create index #  Convention 1 of index naming [DEFAULT] :</description>
    </item>
    
    <item>
      <title>datamart creation guidelines</title>
      <link>http://mritunjay583.github.io/docs/docs/usage-guidelines/datamarts-creations-guidelines/</link>
      <pubDate>Tue, 26 Mar 2019 08:47:11 +0100</pubDate>
      
      <guid>http://mritunjay583.github.io/docs/docs/usage-guidelines/datamarts-creations-guidelines/</guid>
      <description>DataMarts Creation/Updation in DMDB #  Why use datamarts and not access data directly with full SQL from application (the widely/mostly known acceptable way) #   Reusability - With each metric anyone writes it is contributed to Org and will be available to use for others. Numerous users do not have to write same query again. Standard Of metrics definition - When a metric calculation in a single way Org wide, it will be easier to standardize the definition for that metric.</description>
    </item>
    
    <item>
      <title>dmdb usage</title>
      <link>http://mritunjay583.github.io/docs/docs/usage-guidelines/dmdb-usage-guide/</link>
      <pubDate>Tue, 26 Mar 2019 08:47:11 +0100</pubDate>
      
      <guid>http://mritunjay583.github.io/docs/docs/usage-guidelines/dmdb-usage-guide/</guid>
      <description>Definition of Datamart (dm) #  Datamart is a subset / aggregation / filtered / limited by columns of Raw.
Is DMDB right for you? (Use-cases) #  Understanding the raw dataset naming convention #  Convention:
 Latest Based Table - {schema_name}{naming_convention}.{table_name}{primary_key_column_list_on_which_the_latest_is_taken_on}{method}{column_name_convention} eg. Package Scan Latest - raw_u.package_scan__wbn_cs_uid__latest_u Append Only Table - {schema_name}{naming_convention}.{table_name}{column_name_convention} eg. Audit Scan Append - raw_u.audit_scan_u  Quering data Guidelines #    Always action_date as the first filter and never forget to put typecast of bigint in the end.</description>
    </item>
    
    <item>
      <title>metric table design</title>
      <link>http://mritunjay583.github.io/docs/docs/usage-guidelines/metric_table-design-and-usage/</link>
      <pubDate>Tue, 26 Mar 2019 08:47:11 +0100</pubDate>
      
      <guid>http://mritunjay583.github.io/docs/docs/usage-guidelines/metric_table-design-and-usage/</guid>
      <description>Problem Statement (In RTDB) #   The current problem in RTDB is that every metric (i.e. data of every widget) is served by a dedicated table  Maintenance overhead of these tables like bloat, deletion etc   Privelege control management of these metrics tables are not done. Everything is in under public schema and everyone can access every metric Redundancy of metrics i.e. same (similar/overlapping metrics) are calcualated from the very start No structure of creating aggregations over aggregations  Structure of Serving Metrics #   We have categorized the metrics in 2 parts -  Day before Yesterday Metrics and even Before - MATERIALIZED in a table (aka Historical) CURRENT_DAY and PREVIOUS_DAY (IST) of Metrics - NOT MATERIALIZED - LIVE QUERY ONLY (aka recent) -    Why materialization of metrics is required?</description>
    </item>
    
    <item>
      <title>navigation-around-views-and-tables</title>
      <link>http://mritunjay583.github.io/docs/docs/usage-guidelines/navigation-around-views-and-tables/</link>
      <pubDate>Tue, 26 Mar 2019 08:47:11 +0100</pubDate>
      
      <guid>http://mritunjay583.github.io/docs/docs/usage-guidelines/navigation-around-views-and-tables/</guid>
      <description>Query to get table name from view name #  -- referenced_table_name will contain the tablename SELECT * FROM (SELECT u.view_schema AS schema_nameD, u.view_name, u.table_schema AS referenced_table_schema, u.table_name AS referenced_table_name, v.view_definition FROM information_schema.view_table_usage u JOIN information_schema.views v ON u.view_schema = v.table_schema AND u.view_name = v.table_name WHERE u.table_schema NOT IN (&#39;information_schema&#39;, &#39;pg_catalog&#39;) --- CHANGE VIEW NAME HERE AND u.view_name= &#39;{view_name}&#39; ORDER BY u.view_schema, u.view_name) AS VIEW_DETAILS; -- Source https://dataedo.com/kb/query/postgresql/list-tables-used-by-a-view Query to get move around in partition table tree hierarchy #  SELECT * FROM pg_partition_root(table_name); SELECT * FROM pg_partition_ancestors(table_name); SELECT * FROM pg_partition_tree(table_name); </description>
    </item>
    
    <item>
      <title>Offset management</title>
      <link>http://mritunjay583.github.io/docs/docs/usage-guidelines/api/offset-management-apis-usage/</link>
      <pubDate>Tue, 26 Mar 2019 08:47:11 +0100</pubDate>
      
      <guid>http://mritunjay583.github.io/docs/docs/usage-guidelines/api/offset-management-apis-usage/</guid>
      <description>Spark-Structured Streaming Offset Management APIs #  spark-structured streaming has it&amp;rsquo;s own offset management it does not
support storing consumed offset information in consumer group in kafka.
It uses checkpoint location which you provide. we are using s3 as
checkpoint location. Currently there is no APIs in spark-structured
streaming using which we can get information of currently consumed
offsets or reset offsets for current pipeline. We created APIs which
will do all of this work.</description>
    </item>
    
    <item>
      <title>programmatic access and Integration</title>
      <link>http://mritunjay583.github.io/docs/docs/usage-guidelines/programmatic-access-and-integration/</link>
      <pubDate>Tue, 26 Mar 2019 08:47:11 +0100</pubDate>
      
      <guid>http://mritunjay583.github.io/docs/docs/usage-guidelines/programmatic-access-and-integration/</guid>
      <description>Guidelines for programmatic Integration with DMDB #    Use only the user provided to you for your specific application. Even if you have any other credentials like developers credentials, some other application&amp;rsquo;s credentials, etc.; dont use them. Ask for new credentials for each new application/dashboard.
  Connection Timeout (300ms) - Use this while making the connection to DB. If the connection fail within the timeout move further, log error (raise alarms).</description>
    </item>
    
  </channel>
</rss>
